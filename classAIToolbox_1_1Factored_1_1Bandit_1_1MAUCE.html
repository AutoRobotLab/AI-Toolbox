<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AIToolbox: AIToolbox::Factored::Bandit::MAUCE Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">AIToolbox
   </div>
   <div id="projectbrief">A library that offers tools for AI problem solving.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceAIToolbox.html">AIToolbox</a></li><li class="navelem"><a class="el" href="namespaceAIToolbox_1_1Factored.html">Factored</a></li><li class="navelem"><a class="el" href="namespaceAIToolbox_1_1Factored_1_1Bandit.html">Bandit</a></li><li class="navelem"><a class="el" href="classAIToolbox_1_1Factored_1_1Bandit_1_1MAUCE.html">MAUCE</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classAIToolbox_1_1Factored_1_1Bandit_1_1MAUCE-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">AIToolbox::Factored::Bandit::MAUCE Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>This class represents the Multi-Agent Upper Confidence Exploration algorithm.  
 <a href="classAIToolbox_1_1Factored_1_1Bandit_1_1MAUCE.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="MAUCE_8hpp_source.html">MAUCE.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a913e3948b9918bc0d017f4368a050950"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1Bandit_1_1MAUCE.html#a913e3948b9918bc0d017f4368a050950">MAUCE</a> (<a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> a, const std::vector&lt; std::pair&lt; double, std::vector&lt; size_t &gt;&gt;&gt; &amp;rangesAndDependencies)</td></tr>
<tr class="memdesc:a913e3948b9918bc0d017f4368a050950"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic constructor.  <a href="#a913e3948b9918bc0d017f4368a050950">More...</a><br /></td></tr>
<tr class="separator:a913e3948b9918bc0d017f4368a050950"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f5c33677520d013a03da794e0f5035d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1Bandit_1_1MAUCE.html#a4f5c33677520d013a03da794e0f5035d">stepUpdateQ</a> (const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;a, const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aad6527c0695fd67b56fec310055a7bdc">Rewards</a> &amp;rew)</td></tr>
<tr class="memdesc:a4f5c33677520d013a03da794e0f5035d"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function updates the learning process from the previous action and reward.  <a href="#a4f5c33677520d013a03da794e0f5035d">More...</a><br /></td></tr>
<tr class="separator:a4f5c33677520d013a03da794e0f5035d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff27a461e015d0005728a94515534254"><td class="memItemLeft" align="right" valign="top">unsigned&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1Bandit_1_1MAUCE.html#aff27a461e015d0005728a94515534254">getTimestep</a> () const</td></tr>
<tr class="memdesc:aff27a461e015d0005728a94515534254"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function returns the currently set internal timestep.  <a href="#aff27a461e015d0005728a94515534254">More...</a><br /></td></tr>
<tr class="separator:aff27a461e015d0005728a94515534254"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acc42d0ed56d118e27282531430e0110e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1Bandit_1_1MAUCE.html#acc42d0ed56d118e27282531430e0110e">setTimestep</a> (unsigned t)</td></tr>
<tr class="memdesc:acc42d0ed56d118e27282531430e0110e"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function sets the internal timestep.  <a href="#acc42d0ed56d118e27282531430e0110e">More...</a><br /></td></tr>
<tr class="separator:acc42d0ed56d118e27282531430e0110e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f49290c833b5017893848502341c007"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classAIToolbox_1_1Factored_1_1FactoredContainer.html">FactoredContainer</a>&lt; <a class="el" href="structAIToolbox_1_1Factored_1_1Bandit_1_1QFunctionRule.html">QFunctionRule</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAIToolbox_1_1Factored_1_1Bandit_1_1MAUCE.html#a9f49290c833b5017893848502341c007">getQFunctionRules</a> () const</td></tr>
<tr class="memdesc:a9f49290c833b5017893848502341c007"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function obtains the optimal QFunctionRules computed so far.  <a href="#a9f49290c833b5017893848502341c007">More...</a><br /></td></tr>
<tr class="separator:a9f49290c833b5017893848502341c007"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This class represents the Multi-Agent Upper Confidence Exploration algorithm. </p>
<p>This algorithm is similar in spirit to <a class="el" href="classAIToolbox_1_1Factored_1_1Bandit_1_1LLR.html" title="This class represents the Learning with Linear Rewards algorithm. ">LLR</a>, but it performs a much more sophisticated variable elimination step that includes branch-and-bound.</p>
<p>It does this by knowing, via its parameters, the maximum reward range for each group of interdependent agents (max possible reward minus min possible reward). This allows it to estimate the uncertainty around any given joint action, by keeping track for each PartialAction its upper and lower bounds.</p>
<p>During the <a class="el" href="classAIToolbox_1_1Factored_1_1Bandit_1_1VariableElimination.html" title="This class represents the Variable Elimination process. ">VariableElimination</a> step (done with <a class="el" href="classAIToolbox_1_1Factored_1_1Bandit_1_1UCVE.html" title="This class represents the UCVE process. ">UCVE</a>), the uncertainties are tracked during the cross-sums, which allows pruning actions that are known to be suboptimal. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a913e3948b9918bc0d017f4368a050950"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a913e3948b9918bc0d017f4368a050950">&#9670;&nbsp;</a></span>MAUCE()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">AIToolbox::Factored::Bandit::MAUCE::MAUCE </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a>&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::pair&lt; double, std::vector&lt; size_t &gt;&gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>rangesAndDependencies</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic constructor. </p>
<p>This constructor needs to know in advance the groups of agents that need to collaboratively cooperate in order to reach their goal. This is converted in a simple Q-Table containing the learned averages for those groups.</p>
<p>Note: each group must be unique, and all lists of agents must be sorted!</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">a</td><td>The factored action space of the problem. </td></tr>
    <tr><td class="paramname">rangesAndDependencies</td><td>A list of [[range, [agent, ..]], ..] for each subgroup of connected agents. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a9f49290c833b5017893848502341c007"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9f49290c833b5017893848502341c007">&#9670;&nbsp;</a></span>getQFunctionRules()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classAIToolbox_1_1Factored_1_1FactoredContainer.html">FactoredContainer</a>&lt;<a class="el" href="structAIToolbox_1_1Factored_1_1Bandit_1_1QFunctionRule.html">QFunctionRule</a>&gt; AIToolbox::Factored::Bandit::MAUCE::getQFunctionRules </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function obtains the optimal QFunctionRules computed so far. </p>
<p>These rules skip the exploration part, to allow the creation of a policy using the learned QFunction (since otherwise this algorithm would forever explore).</p>
<p>Note that this function must perform a complete copy of all internal rules, as those contain the exploration factors of UCB1 baked in.</p>
<dl class="section return"><dt>Returns</dt><dd>The learned optimal QFunctionRules. </dd></dl>

</div>
</div>
<a id="aff27a461e015d0005728a94515534254"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff27a461e015d0005728a94515534254">&#9670;&nbsp;</a></span>getTimestep()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned AIToolbox::Factored::Bandit::MAUCE::getTimestep </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function returns the currently set internal timestep. </p>
<dl class="section return"><dt>Returns</dt><dd>The currently set internal timestep. </dd></dl>

</div>
</div>
<a id="acc42d0ed56d118e27282531430e0110e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acc42d0ed56d118e27282531430e0110e">&#9670;&nbsp;</a></span>setTimestep()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void AIToolbox::Factored::Bandit::MAUCE::setTimestep </td>
          <td>(</td>
          <td class="paramtype">unsigned&#160;</td>
          <td class="paramname"><em>t</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function sets the internal timestep. </p>
<p>This function normally does not need to be called since <a class="el" href="classAIToolbox_1_1Factored_1_1Bandit_1_1MAUCE.html#a4f5c33677520d013a03da794e0f5035d" title="This function updates the learning process from the previous action and reward. ">stepUpdateQ()</a> automatically increases the timestep. This function is provided if that functionality is not enough for some reason.</p>
<p>Keep in mind that stepUpdateQ will first increase the internal timestep, then use the increased one. So to signal that this is going to be the first timestep, the input should be 0, and so on.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">t</td><td>The new internal timestep. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a4f5c33677520d013a03da794e0f5035d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f5c33677520d013a03da794e0f5035d">&#9670;&nbsp;</a></span>stepUpdateQ()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> AIToolbox::Factored::Bandit::MAUCE::stepUpdateQ </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aa30fc73167a9c8e913053059e23f9692">Action</a> &amp;&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="namespaceAIToolbox_1_1Factored.html#aad6527c0695fd67b56fec310055a7bdc">Rewards</a> &amp;&#160;</td>
          <td class="paramname"><em>rew</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function updates the learning process from the previous action and reward. </p>
<p>This function automatically increases the current internal timestep counter.</p>
<p>The rewards must be in the same order as the groups were given in the constructor.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">a</td><td>The action performed in the previous timestep. </td></tr>
    <tr><td class="paramname">rew</td><td>The rewards obtained in the previous timestep, one per agent group.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The new optimal action to be taken at the next timestep. </dd></dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>include/AIToolbox/Factored/Bandit/Algorithms/<a class="el" href="MAUCE_8hpp_source.html">MAUCE.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Tue Sep 11 2018 11:45:46 for AIToolbox by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
